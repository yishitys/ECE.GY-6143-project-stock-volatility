# 已完成任务记录

**项目名称**: 基于社交媒体讨论量的股票波动率预测  
**课程**: ECE.GY 6143 - Machine Learning  
**团队成员**: Yishi Tang, Yuxin  
**最后更新**: 2025-12-05

---

## 📋 项目概述

本项目旨在使用Reddit社交媒体讨论量来预测股票短期波动率（下一小时）。与传统的情绪分析不同，我们专注于讨论**量**，并使用**文本嵌入**来捕获帖子的语义信息。

---

## ✅ 已完成任务清单

### 1. 项目初始化和环境搭建

#### 1.1 项目结构创建
- ✅ 创建了完整的项目目录结构
  - `data/raw/` - 原始Reddit数据存储
  - `data/processed/` - 处理后的数据
  - `data/stock_prices/` - 股票价格数据
  - `src/data_loading/` - 数据加载模块
  - `src/preprocessing/` - 数据预处理模块
  - `src/data_analysis/` - 数据分析模块

#### 1.2 依赖管理
- ✅ 创建了 `requirements.txt` 文件
- ✅ 配置了核心依赖包：
  - `yfinance` - 股票价格数据获取
  - `pandas`, `numpy` - 数据处理
  - `h5py`, `pytables` - H5格式数据支持

#### 1.3 文档编写
- ✅ 创建了详细的 `README.md`（英文）
- ✅ 创建了 `README_CN.md`（中文）
- ✅ 文档包含项目目标、技术方案、实施计划等

---

### 2. 数据收集与加载

#### 2.1 Reddit数据收集
- ✅ 从Kaggle下载Reddit Finance数据集
- ✅ 数据来源：多个金融相关子版块
  - `r/stocks`, `r/wallstreetbets`, `r/investing`, `r/stockmarket`
  - `r/options`, `r/pennystocks`, `r/finance`, `r/forex`
  - `r/personalfinance`, `r/robinhood`, `r/gme`
  - 以及其他相关子版块
- ✅ 数据格式：CSV和H5格式
- ✅ 数据时间范围：2021年全年

#### 2.2 Reddit数据加载模块
- ✅ 实现了 `load_reddit_data.py`
  - 支持从CSV和H5文件加载数据
  - 自动过滤无效帖子（已删除、已移除）
  - 解析时间戳并转换为UTC
  - 支持多子版块数据合并
  - 提取文本内容（title + selftext）

#### 2.3 股票价格数据收集
- ✅ 实现了 `load_stock_data.py`
  - 使用 `yfinance` API获取历史价格数据
  - 支持12只股票的数据收集：
    - **高优先级**: GME, AMC, BB, PLTR, TSLA
    - **中优先级**: NIO, SOFI, HOOD, SNDL
    - **低优先级**: AAPL, AMD, NOK
  - 将每日数据扩展为每小时数据（交易时间内）
  - 处理时区转换（EST → UTC）
  - 保存为CSV格式便于后续使用

#### 2.4 股票数据统计
- ✅ 成功收集了12只股票的完整数据
- ✅ 数据时间范围：2021-01-04 至 2021-12-30
- ✅ 每只股票约2000+条小时级记录
- ✅ 数据质量：无缺失值、无异常值

---

### 3. 数据预处理

#### 3.1 文本清洗模块
- ✅ 实现了 `clean_text.py`
  - 移除已删除和已移除的帖子
  - 文本清理和标准化
  - 处理缺失文本内容
  - 生成统一的文本内容字段

#### 3.2 时间戳对齐模块
- ✅ 实现了 `align_timestamps.py`
  - 将Reddit数据按小时聚合
  - 计算每小时统计特征：
    - 帖子数量（post_count）
    - 总评论数（total_comments）
    - 总得分（total_score）
    - 唯一作者数（unique_authors）
  - 将股票数据对齐到小时级粒度
  - 处理时区差异

#### 3.3 数据合并模块
- ✅ 实现了 `merge_data.py`
  - 合并Reddit和股票数据
  - 基于时间戳进行对齐
  - 处理缺失值
  - 添加数据可用性标志
  - 数据验证功能

#### 3.4 主预处理流程
- ✅ 实现了 `preprocess.py`
  - 整合所有预处理步骤
  - 支持命令行参数
  - 完整的日志记录
  - 自动化预处理流程

#### 3.5 预处理结果
- ✅ 成功处理GME股票数据
  - 生成 `merged_data_GME.csv`
  - 包含2,002条小时级记录
  - 时间范围：2021-01-04 至 2021-12-30
  - 数据完整性：100%（无缺失值）
  - Reddit数据：168,158个帖子，8,505,112条评论
  - 数据质量评分：100/100

---

### 4. 数据分析与可视化

#### 4.1 股票价格数据分析
- ✅ 实现了 `analyze_stock_data.py`
  - 完整的股票数据分析器类
  - 计算基本统计信息
  - 生成多种可视化图表

#### 4.2 统计分析
- ✅ 为每只股票计算了详细统计：
  - 价格统计（开盘、最高、最低、收盘）
  - 成交量统计
  - 收益率和波动率分析
  - 数据质量评估
  - 价格极值识别

#### 4.3 可视化图表生成
- ✅ 生成了多种分析图表：
  - **价格走势图**：每只股票的单独价格趋势图
  - **综合价格对比图**：所有股票的价格走势对比
  - **分布图**：价格、收益率、成交量、波动率分布
  - **相关性热力图**：股票之间的价格相关性
  - **波动率对比图**：年化波动率和平均收益率对比
- ✅ 所有图表保存在 `data/stock_prices/figures/` 目录

#### 4.4 分析报告生成
- ✅ 生成了详细的统计报告
  - `data/stock_prices/statistics_report.md`
  - 包含每只股票的完整统计分析
  - 包含综合对比分析
  - 包含数据质量评估

---

### 5. 报告生成

#### 5.1 预处理报告
- ✅ 实现了 `generate_report.py`
  - 自动生成数据预处理报告
  - 包含数据概览、统计信息、质量评估
- ✅ 生成了GME的预处理报告
  - `data/processed/preprocessing_report.md`
  - 包含详细的Reddit和股票数据统计
  - 包含时间分布分析
  - 包含数据质量评分

#### 5.2 数据质量评估
- ✅ 实现了完整的数据验证流程
- ✅ 所有数据通过质量检查：
  - 无缺失值
  - 无异常值
  - 时间戳对齐正确
  - 数据类型正确

---

## 📊 数据统计摘要

### Reddit数据统计（GME示例）
- **总帖子数**: 168,158
- **总评论数**: 8,505,112
- **唯一作者数**: 158,744
- **平均每小时帖子数**: 84.00
- **数据时间跨度**: 360天（2021年全年）

### 股票数据统计
- **已收集股票数**: 12只
- **总数据行数**: 22,952行
- **数据完整性**: 100%
- **时间范围**: 2021-01-04 至 2021-12-30

### 合并数据统计（GME）
- **总记录数**: 2,002条
- **数据可用率**: 100%
- **同时有Reddit和股票数据**: 100%

---

## 🎯 技术实现亮点

### 1. 数据处理管道
- ✅ 模块化设计，易于维护和扩展
- ✅ 完整的错误处理和日志记录
- ✅ 支持多种数据格式（CSV, H5）
- ✅ 高效的数据加载和处理

### 2. 时间对齐处理
- ✅ 正确处理时区转换（EST ↔ UTC）
- ✅ 处理交易时间限制（9:30 AM - 4:00 PM EST）
- ✅ 处理非交易日和节假日
- ✅ 小时级数据聚合

### 3. 数据质量保证
- ✅ 自动数据验证
- ✅ 缺失值检测和处理
- ✅ 异常值检测
- ✅ 数据质量评分系统

### 4. 可视化分析
- ✅ 多种图表类型
- ✅ 高质量图表输出（300 DPI）
- ✅ 中文支持
- ✅ 自动化报告生成

---

## 📁 生成的文件清单

### 数据文件
- `data/processed/merged_data_GME.csv` - GME合并数据（2,002行）
- `data/processed/reddit_cleaned.csv` - 清洗后的Reddit数据
- `data/stock_prices/*_2021.csv` - 12只股票的原始价格数据

### 报告文件
- `data/processed/preprocessing_report.md` - GME预处理报告
- `data/stock_prices/statistics_report.md` - 股票价格统计报告

### 可视化文件
- `data/stock_prices/figures/price_trends.png` - 价格走势对比
- `data/stock_prices/figures/distributions.png` - 分布分析
- `data/stock_prices/figures/correlation_heatmap.png` - 相关性热力图
- `data/stock_prices/figures/volatility_comparison.png` - 波动率对比
- `data/stock_prices/figures/{SYMBOL}_price_trend.png` - 各股票单独价格图（12张）

### 特征工程文件
- `src/feature_engineering/calculate_target.py` - 目标变量计算模块
- `src/feature_engineering/generate_embeddings.py` - 文本嵌入生成模块
- `src/feature_engineering/aggregate_features.py` - 特征聚合模块
- `src/feature_engineering/technical_indicators.py` - 技术指标计算模块
- `src/feature_engineering/feature_pipeline.py` - 特征工程主流程
- `data/processed/features_GME.csv` - 完整特征数据集（✅ 已生成，444个特征，2,001条记录）
- `data/processed/embeddings/embeddings_all-MiniLM-L6-v2.pkl` - 文本嵌入缓存（✅ 已生成）
- `data/processed/feature_report_GME.md` - 特征工程报告（✅ 已生成）
- `data/processed/target_analysis_GME.md` - 目标变量分析报告（✅ 已生成）

### 模型文件（新增）
- `src/models/xgboost_model.py` - XGBoost模型实现
- `src/models/train.py` - 训练脚本
- `src/models/lstm_model.py` - LSTM模型实现
- `models/xgboost_{SYMBOL}.pkl` - 训练好的XGBoost模型（待生成）
- `models/lstm_{SYMBOL}.pth` - 训练好的LSTM模型（待生成）

### 评估文件（新增）
- `src/evaluation/evaluate.py` - 评估指标计算
- `src/evaluation/visualize_results.py` - 结果可视化
- `results/evaluation_report_{MODEL}_{SYMBOL}.md` - 评估报告（待生成）
- `results/figures/{MODEL}_predictions_{SYMBOL}.png` - 预测对比图（待生成）
- `results/figures/{MODEL}_residuals_{SYMBOL}.png` - 残差分析图（待生成）
- `results/figures/{MODEL}_errors_{SYMBOL}.png` - 误差分布图（待生成）
- `results/figures/{MODEL}_importance_{SYMBOL}.png` - 特征重要性图（待生成）
- `results/figures/model_comparison_{SYMBOL}.png` - 模型对比图（待生成）

### 主训练脚本（新增）
- `src/train_main.py` - 统一训练入口

---

### 6. 特征工程

#### 6.1 依赖包更新
- ✅ 更新了 `requirements.txt`
  - 添加 `sentence-transformers>=2.0.0` - 文本嵌入生成
  - 添加 `scikit-learn>=1.0.0` - 机器学习工具和评估指标
  - 添加 `xgboost>=1.5.0` - 基线梯度提升模型
  - 添加 `lightgbm>=3.3.0` - 替代基线模型
  - 添加 `torch>=1.10.0` - LSTM模型框架
  - 添加 `matplotlib>=3.5.0`, `seaborn>=0.11.0` - 可视化

#### 6.2 目标变量计算
- ✅ 实现了 `calculate_target.py`
  - 计算下一小时的波动率作为预测目标
  - 支持多种波动率定义：
    - 对数收益率绝对值：`|log(close_{t+1}/close_t)|`
    - 价格范围：`(high - low) / close` for next hour
    - 已实现波动率（标准差）
  - 处理边界情况（最后一条记录无下一小时数据）
  - 目标变量分布分析和报告生成

#### 6.3 文本嵌入生成
- ✅ 实现了 `generate_embeddings.py`
  - 使用 `sentence-transformers` 库生成文本嵌入
  - 支持多种模型（`all-MiniLM-L6-v2`, `all-mpnet-base-v2`等）
  - 为每个Reddit帖子生成嵌入向量（384或768维）
  - 实现缓存机制，避免重复计算
  - 支持批量处理和进度跟踪
  - 处理空文本（使用零向量）
  - 保存嵌入到 `data/processed/embeddings/` 目录

#### 6.4 特征聚合
- ✅ 实现了 `aggregate_features.py`
  - 将帖子级嵌入聚合为小时级特征
  - 实现多种聚合策略：
    - **Mean Pooling**: 平均所有帖子嵌入
    - **Weighted Mean**: 根据score或comments加权平均
    - **Max Pooling**: 取每个维度的最大值
  - 处理空小时（无帖子时使用零向量或前值填充）
  - 结合现有的Reddit统计特征
  - 合并聚合后的嵌入和Reddit统计特征

#### 6.5 技术指标计算
- ✅ 实现了 `technical_indicators.py`
  - **价格特征**：
    - 收益率（returns）和对数收益率（log returns）
    - 价格变化百分比
  - **移动平均**：
    - SMA (Simple Moving Average): 5, 10, 20小时
    - EMA (Exponential Moving Average): 5, 10, 20小时
  - **波动率指标**：
    - 历史波动率（rolling std of returns）
    - ATR (Average True Range)
  - **动量指标**：
    - RSI (Relative Strength Index)
    - MACD (Moving Average Convergence Divergence)
  - **成交量指标**：
    - 成交量移动平均
    - 成交量变化率
  - **时间序列特征**：
    - 滞后特征（lag features）：前1, 2, 3小时
    - 滚动统计：滚动窗口内的均值、标准差、最大值、最小值

#### 6.6 特征工程主流程
- ✅ 实现了 `feature_pipeline.py`
  - 整合所有特征工程步骤
  - 自动化特征生成流程：
    1. 加载合并数据
    2. 计算目标变量
    3. 生成文本嵌入（如果尚未生成）
    4. 聚合文本特征
    5. 计算技术指标
    6. 合并所有特征
    7. 处理缺失值
    8. 保存最终特征数据集
  - 生成特征工程报告
  - 支持命令行参数

#### 6.7 特征工程执行结果（2025-12-10）
- ✅ 成功执行完整特征工程流程（GME股票）
- ✅ 生成的特征数据集：`data/processed/features_GME.csv`
  - **总特征数**: 444个
  - **总记录数**: 2,001条（删除了最后一条无目标变量的记录）
  - **时间范围**: 2021-01-04 至 2021-12-30
  - **数据质量**: 100%（无缺失值、无重复记录）
- ✅ 文本嵌入生成：
  - 处理了374,673个Reddit帖子
  - 使用 `all-MiniLM-L6-v2` 模型生成384维嵌入
  - 嵌入已缓存到 `data/processed/embeddings/embeddings_all-MiniLM-L6-v2.pkl`
  - 聚合到8,732小时
- ✅ 生成报告文件：
  - `data/processed/feature_report_GME.md` - 特征工程详细报告
  - `data/processed/target_analysis_GME.md` - 目标变量分析报告
- ✅ 修复的问题：
  - 修复了pandas `fillna(method=)` 弃用警告（改用 `ffill()` 和 `bfill()`）
  - 修复了特征聚合时丢失股票价格数据的问题
  - 改进了技术指标列名自动检测逻辑

---

### 7. 模型开发

#### 7.1 XGBoost基线模型
- ✅ 实现了 `xgboost_model.py`
  - 完整的XGBoost回归模型类
  - 支持回归任务（波动率预测）
  - 特征准备和数据预处理
  - 模型训练和预测功能
  - 特征重要性分析
  - 模型保存和加载
  - 支持早停机制

#### 7.2 训练脚本
- ✅ 实现了 `train.py`
  - 数据划分（训练/验证/测试集，按时间顺序）
  - 支持多种模型（XGBoost, LightGBM等）
  - 时间序列交叉验证
  - 超参数调优（GridSearch和RandomSearch）
  - 完整的训练流程编排
  - 结果保存和报告生成

#### 7.3 LSTM时间序列模型
- ✅ 实现了 `lstm_model.py`
  - LSTM模型架构：
    - 输入层：时间序列窗口（可配置，默认24小时）
    - LSTM层：1-2层，可配置单元数
    - Dropout层：防止过拟合
    - 全连接层：输出预测
  - 时间序列数据集类（TimeSeriesDataset）
  - 数据准备：
    - 时间序列窗口构建
    - 序列标准化（StandardScaler）
  - 训练循环：
    - 损失函数（MSE for regression）
    - 优化器（Adam）
    - 早停机制（Early Stopping）
  - 模型评估和预测
  - 模型保存和加载

---

### 8. 模型评估

#### 8.1 评估指标
- ✅ 实现了 `evaluate.py`
  - **回归指标**：
    - RMSE (Root Mean Squared Error)
    - MAE (Mean Absolute Error)
    - R² Score (决定系数)
    - MAPE (Mean Absolute Percentage Error)
    - Directional Accuracy（方向预测准确率）
    - Correlation（相关系数）
  - **分类指标**（预留接口）：
    - Accuracy, Precision, Recall, F1-Score
    - ROC-AUC, PR-AUC
    - Confusion Matrix
  - 评估报告生成（Markdown格式）

#### 8.2 结果可视化
- ✅ 实现了 `visualize_results.py`
  - **预测对比图**：预测值vs实际值时间序列图
  - **残差分析图**：
    - 残差时间序列
    - 残差分布直方图
    - 残差vs预测值散点图
    - Q-Q图（正态性检验）
  - **误差分布图**：
    - 绝对误差分布
    - 相对误差分布
  - **特征重要性图**：Top N特征重要性可视化
  - **模型性能对比图**：多个模型的性能对比
  - 所有图表保存为高质量PNG（300 DPI）

---

### 9. 统一训练入口

#### 9.1 主训练脚本
- ✅ 实现了 `train_main.py`
  - 统一的训练入口，整合所有组件
  - 命令行参数解析
  - 支持选择模型类型（XGBoost/LSTM/Both）
  - 支持选择股票（目前支持GME，可扩展）
  - 自动特征工程（如果特征数据不存在）
  - 完整的训练流程编排
  - 自动生成评估报告和可视化图表
  - 模型对比功能（当训练多个模型时）

---

## 🔄 下一步计划

### 待完成任务

1. **模型训练和实验**
   - [x] 运行完整的特征工程流程生成GME特征数据集 ✅
   - [ ] 训练XGBoost模型并评估性能
   - [ ] 训练LSTM模型并评估性能
   - [ ] 对比两个模型的性能
   - [ ] 超参数调优以获得最佳性能

2. **模型优化**
   - [ ] 特征选择（减少维度，提高效率）
   - [ ] 尝试不同的嵌入模型
   - [ ] 尝试不同的聚合策略
   - [ ] 尝试Transformer模型（可选）

3. **扩展应用**
   - [ ] 扩展到其他股票（AMC, TSLA等）
   - [ ] 多股票联合训练
   - [ ] 实时预测系统（可选）

4. **文档完善**
   - [ ] 模型训练文档和使用说明
   - [ ] API使用文档
   - [ ] 最终项目报告
   - [ ] 实验结果分析报告

---

## 📝 备注

- 所有代码都包含详细的中文注释
- 数据预处理流程已完全自动化
- 特征工程流程已完全自动化
- 项目结构清晰，易于扩展
- 数据质量优秀，为模型训练打下良好基础
- 模型代码已实现，可以直接使用 `train_main.py` 进行训练
- 支持XGBoost和LSTM两种模型，可以对比性能
- 所有模块都经过lint检查，无错误

## 🚀 快速开始

### 训练模型

```bash
# 训练XGBoost模型（会自动进行特征工程）
python src/train_main.py --symbol GME --model xgboost --build-features

# 训练LSTM模型
python src/train_main.py --symbol GME --model lstm

# 训练两个模型并对比
python src/train_main.py --symbol GME --model both --build-features
```

### 单独运行特征工程

```bash
python src/feature_engineering/feature_pipeline.py --symbol GME
```

---

**最后更新**: 2025-12-10  
**状态**: 特征工程流程已成功执行 ✅，可以开始模型训练

---

## 📊 新增数据统计摘要

### 特征工程输出（实际结果 - GME）
- **特征数量**: 444 个特征 ✅
  - 文本嵌入特征：384维（使用all-MiniLM-L6-v2）
  - Reddit统计特征：4个（post_count, total_comments, total_score, unique_authors）
  - 技术指标特征：50个（收益率、移动平均、RSI、MACD、波动率、成交量、滞后特征等）
  - 股票价格特征：5个（open, high, low, close, volume）
  - 其他特征：1个（timestamp）
- **目标变量**: 2个
  - `target_volatility_log_return_abs`: 对数收益率绝对值（主要目标）
  - `target_volatility_price_range`: 价格范围波动率
- **数据记录**: 2,001条（时间范围：2021-01-04 至 2021-12-30）
- **数据质量**: 100%（无缺失值、无重复记录）
- **Reddit数据**: 374,673个帖子，聚合到8,732小时

### 模型架构
- **XGBoost模型**:
  - 默认参数：n_estimators=100, max_depth=6, learning_rate=0.1
  - 支持早停和超参数调优
- **LSTM模型**:
  - 默认参数：sequence_length=24, hidden_size=64, num_layers=2
  - 支持Dropout和早停机制

---

## 🎯 新增技术实现亮点

### 1. 特征工程管道
- ✅ 完全自动化的特征生成流程
- ✅ 支持缓存机制，避免重复计算
- ✅ 模块化设计，易于扩展和维护
- ✅ 完整的特征工程报告生成

### 2. 模型实现
- ✅ 两种不同类型的模型（树模型 vs 深度学习）
- ✅ 时间序列数据正确处理（保持时间顺序）
- ✅ 完整的训练、评估、保存流程
- ✅ 支持模型对比和性能分析

### 3. 评估和可视化
- ✅ 全面的评估指标（回归和分类）
- ✅ 高质量的可视化图表
- ✅ 自动生成评估报告
- ✅ 支持模型性能对比

### 4. 易用性
- ✅ 统一的命令行接口
- ✅ 自动特征工程（如果数据不存在）
- ✅ 完整的日志记录
- ✅ 详细的错误处理

